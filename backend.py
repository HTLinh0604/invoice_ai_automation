# file: backend.py 

# --- I. KHAI B√ÅO TH∆Ø VI·ªÜN ---
import numpy as np
import torch
import torchvision.transforms as T
from PIL import Image  # Pillow: Th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh c∆° b·∫£n (m·ªü, resize, chuy·ªÉn ƒë·ªïi).
from transformers import pipeline  # Th∆∞ vi·ªán c·ªßa Hugging Face ƒë·ªÉ d·ªÖ d√†ng s·ª≠ d·ª•ng c√°c m√¥ h√¨nh AI.
import requests
import pytesseract  # Wrapper Python cho Tesseract OCR Engine.
import re
import cv2  # OpenCV: Th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh v√† th·ªã gi√°c m√°y t√≠nh n√¢ng cao.
from huggingface_hub import login
from dotenv import load_dotenv  # T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env.
import random
import os
import json
import google.generativeai as genai  # SDK c·ªßa Google cho c√°c m√¥ h√¨nh Gemini.

# --- II. C·∫§U H√åNH BAN ƒê·∫¶U ---

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng (v√≠ d·ª•: API keys) t·ª´ file .env.
load_dotenv()
# L·∫•y token c·ªßa Hugging Face ƒë·ªÉ c√≥ th·ªÉ t·∫£i c√°c m√¥ h√¨nh private ho·∫∑c c√≥ y√™u c·∫ßu x√°c th·ª±c.
hf_token = os.getenv("HF_TOKEN")
if not hf_token:
    raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y HF_TOKEN trong file .env")

# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ƒë·∫øn file th·ª±c thi c·ªßa Tesseract OCR tr√™n Windows.
# ƒê√¢y l√† b∆∞·ªõc b·∫Øt bu·ªôc n·∫øu Tesseract kh√¥ng ƒë∆∞·ª£c th√™m v√†o bi·∫øn m√¥i tr∆∞·ªùng PATH c·ªßa h·ªá th·ªëng.
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'


# --- III. C√ÅC H√ÄM TI·ªÄN X·ª¨ L√ù ·∫¢NH (IMAGE PREPROCESSING) ---
# M·ª•c ƒë√≠ch: C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ·∫£nh ƒë·∫ßu v√†o ƒë·ªÉ Tesseract OCR c√≥ th·ªÉ nh·∫≠n d·∫°ng vƒÉn b·∫£n ch√≠nh x√°c h∆°n.

def resize_image_in_memory(input_image: Image.Image, target_dpi=300, min_physical_size_inches=4) -> Image.Image:
    """
    Thay ƒë·ªïi k√≠ch th∆∞·ªõc ·∫£nh trong b·ªô nh·ªõ ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c DPI (dots per inch) m·ª•c ti√™u.
    OCR ho·∫°t ƒë·ªông t·ªët nh·∫•t v·ªõi ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i kho·∫£ng 300 DPI.
    """
    im = input_image
    width_px, height_px = im.size
    # T√≠nh to√°n s·ªë pixel t·ªëi thi·ªÉu c·∫ßn c√≥ d·ª±a tr√™n DPI m·ª•c ti√™u.
    min_pixels = int(min_physical_size_inches * target_dpi)
    
    # N·∫øu chi·ªÅu nh·ªè nh·∫•t c·ªßa ·∫£nh th·∫•p h∆°n ng∆∞·ª°ng, ti·∫øn h√†nh ph√≥ng to.
    if min(width_px, height_px) < min_pixels:
        scale_factor = min_pixels / min(width_px, height_px)
        new_size = (int(width_px * scale_factor), int(height_px * scale_factor))
        im = im.resize(new_size, Image.LANCZOS) # D√πng thu·∫≠t to√°n LANCZOS cho k·∫øt qu·∫£ resize ch·∫•t l∆∞·ª£ng cao.
        print(f"üñºÔ∏è ƒê√£ thay ƒë·ªïi k√≠ch th∆∞·ªõc ·∫£nh trong b·ªô nh·ªõ th√†nh {new_size[0]} √ó {new_size[1]} pixels")
    else:
        print("üñºÔ∏è ·∫¢nh ƒë·ªß l·ªõn, kh√¥ng c·∫ßn thay ƒë·ªïi k√≠ch th∆∞·ªõc.")
    return im

def auto_morphology(thresh: np.ndarray) -> np.ndarray:
    """
    √Åp d·ª•ng c√°c ph√©p bi·∫øn ƒë·ªïi h√¨nh th√°i h·ªçc (morphological transformations) m·ªôt c√°ch t·ª± ƒë·ªông.
    M·ª•c ƒë√≠ch l√† ƒë·ªÉ l√†m li·ªÅn c√°c k√Ω t·ª± b·ªã ƒë·ª©t g√£y ho·∫∑c lo·∫°i b·ªè c√°c nhi·ªÖu nh·ªè.
    """
    # T√≠nh to√°n "m·∫≠t ƒë·ªô" c·ªßa c√°c pixel vƒÉn b·∫£n (m√†u tr·∫Øng) tr√™n ·∫£nh.
    text_pixels = cv2.countNonZero(thresh)
    total_pixels = thresh.shape[0] * thresh.shape[1]
    density = text_pixels / total_pixels
    
    # D·ª±a v√†o m·∫≠t ƒë·ªô ƒë·ªÉ ch·ªçn k√≠ch th∆∞·ªõc kernel ph√π h·ª£p.
    # VƒÉn b·∫£n c√†ng th∆∞a -> kernel c√†ng l·ªõn ƒë·ªÉ k·∫øt n·ªëi c√°c ph·∫ßn ·ªü xa nhau.
    if density > 0.10: ksize = (1, 1)
    elif density > 0.05: ksize = (3, 3)
    elif density > 0.01: ksize = (5, 5)
    else: ksize = (7, 7)
    
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize)
    # Dilate (gi√£n n·ªü) ƒë·ªÉ l√†m c√°c n√©t ch·ªØ ƒë·∫≠m h∆°n, li·ªÅn l·∫°i.
    dilated = cv2.dilate(thresh, kernel, iterations=1)
    # Erode (co l·∫°i) ƒë·ªÉ tr·∫£ c√°c n√©t ch·ªØ v·ªÅ k√≠ch th∆∞·ªõc ban ƒë·∫ßu.
    # C·∫∑p DILATE-ERODE ƒë∆∞·ª£c g·ªçi l√† ph√©p "Closing", gi√∫p l·∫•p c√°c l·ªó nh·ªè trong k√Ω t·ª±.
    closed = cv2.erode(dilated, kernel, iterations=1)
    return closed

def preprocess_pipeline(image: Image.Image) -> np.ndarray:
    """
    Pipeline ho√†n ch·ªânh cho vi·ªác ti·ªÅn x·ª≠ l√Ω m·ªôt ·∫£nh.
    """
    # 1. Resize ·∫£nh ƒë·ªÉ ƒë·∫£m b·∫£o ƒë·ªô ph√¢n gi·∫£i ƒë·ªß t·ªët.
    resized_image = resize_image_in_memory(image)
    # 2. Chuy·ªÉn t·ª´ ƒë·ªãnh d·∫°ng PIL Image sang m·∫£ng NumPy c·ªßa OpenCV.
    opencv_image = np.array(resized_image)
    # 3. ƒê·∫£m b·∫£o ·∫£nh ·ªü ƒë·ªãnh d·∫°ng BGR m√† OpenCV th∆∞·ªùng d√πng.
    if opencv_image.ndim == 3 and opencv_image.shape[2] == 3:
        opencv_image = cv2.cvtColor(opencv_image, cv2.COLOR_RGB2BGR)
    # 4. Chuy·ªÉn sang ·∫£nh x√°m (grayscale).
    gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)
    # 5. L√†m m·ªù ·∫£nh n·ªÅn ƒë·ªÉ lo·∫°i b·ªè c√°c bi·∫øn th·ªÉ √°nh s√°ng kh√¥ng ƒë·ªìng ƒë·ªÅu.
    background = cv2.GaussianBlur(gray, (55, 55), 0)
    # 6. "L√†m ph·∫≥ng" ·∫£nh b·∫±ng c√°ch chia ·∫£nh g·ªëc cho ·∫£nh n·ªÅn.
    flattened = cv2.divide(gray, background, scale=255)
    # 7. Ph√¢n ng∆∞·ª°ng (thresholding) ƒë·ªÉ bi·∫øn ·∫£nh th√†nh ·∫£nh nh·ªã ph√¢n (ƒëen-tr·∫Øng).
    #    S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p OTSU ƒë·ªÉ t·ª± ƒë·ªông t√¨m ng∆∞·ª°ng t·ªëi ∆∞u.
    thresh = cv2.threshold(flattened, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]
    # 8. √Åp d·ª•ng ph√©p bi·∫øn ƒë·ªïi h√¨nh th√°i h·ªçc ƒë·ªÉ l√†m s·∫°ch ·∫£nh cu·ªëi c√πng.
    closed = auto_morphology(thresh)
    return closed

# --- IV. TR√çCH XU·∫§T V√Ä S·ª¨A L·ªñI VƒÇN B·∫¢N ---

def extract_text_from_image(image_path: str) -> str:
    """
    H√†m tr√≠ch xu·∫•t vƒÉn b·∫£n th√¥ t·ª´ m·ªôt file ·∫£nh.
    """
    img = Image.open(image_path)
    # √Åp d·ª•ng pipeline ti·ªÅn x·ª≠ l√Ω ƒë·ªÉ c√≥ ·∫£nh ch·∫•t l∆∞·ª£ng t·ªët nh·∫•t cho OCR.
    processed_img = preprocess_pipeline(img)
    # G·ªçi Tesseract ƒë·ªÉ th·ª±c hi·ªán nh·∫≠n d·∫°ng k√Ω t·ª± quang h·ªçc, ch·ªâ ƒë·ªãnh ng√¥n ng·ªØ l√† ti·∫øng Vi·ªát.
    text = pytesseract.image_to_string(processed_img, lang='vie')
    return text

# Ki·ªÉm tra xem c√≥ GPU (CUDA) kh√¥ng ƒë·ªÉ tƒÉng t·ªëc c√°c m√¥ h√¨nh AI.
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"‚è≥ ƒêang t·∫£i m√¥ h√¨nh s·ª≠a l·ªói vƒÉn b·∫£n...")
# T·∫£i pipeline s·ª≠a l·ªói ch√≠nh t·∫£ ti·∫øng Vi·ªát t·ª´ Hugging Face.
corrector = pipeline("text2text-generation", model="bmd1905/vietnamese-correction-v2")
MAX_LENGTH = 512 # TƒÉng gi·ªõi h·∫°n ƒë·ªÉ x·ª≠ l√Ω c√°c h√≥a ƒë∆°n d√†i.1024
print("üëç M√¥ h√¨nh s·ª≠a l·ªói vƒÉn b·∫£n ƒë√£ s·∫µn s√†ng.")

def correct_text(text: str) -> str:
    """
    S·ª≠a c√°c l·ªói ch√≠nh t·∫£ v√† l·ªói OCR trong vƒÉn b·∫£n ƒë·∫ßu v√†o.
    """
    # `pipeline` c·ªßa transformers x·ª≠ l√Ω vi·ªác chia nh·ªè vƒÉn b·∫£n d√†i th√†nh c√°c batch.
    predictions = corrector(text, max_length=MAX_LENGTH)
    return predictions[0]['generated_text']

# --- V. TR√çCH XU·∫§T TH√îNG TIN C√ì C·∫§U TR√öC B·∫∞NG LLM ---

# L·∫•y danh s√°ch c√°c API key c·ªßa Gemini t·ª´ bi·∫øn m√¥i tr∆∞·ªùng.
keys_str = os.getenv("GEMINI_KEYS")
if not keys_str:
    raise ValueError("‚ùå Kh√¥ng t√¨m th·∫•y GEMINI_KEYS trong file .env")
# T√°ch chu·ªói key th√†nh m·ªôt danh s√°ch, lo·∫°i b·ªè c√°c kho·∫£ng tr·∫Øng th·ª´a.
GEMINI_KEYS = [key.strip() for key in keys_str.split(",") if key.strip()]
# Ch·ªçn ng·∫´u nhi√™n m·ªôt key t·ª´ danh s√°ch ƒë·ªÉ s·ª≠ d·ª•ng.
# ƒê√¢y l√† m·ªôt k·ªπ thu·∫≠t t·ªët ƒë·ªÉ ph√¢n ph·ªëi t·∫£i ho·∫∑c d√πng key d·ª± ph√≤ng n·∫øu m·ªôt key h·∫øt h·∫°n ng·∫°ch.
selected_key = random.choice(GEMINI_KEYS)
print(f"üîê ƒêang s·ª≠ d·ª•ng Gemini API key: {selected_key[:5]}...")
# C·∫•u h√¨nh th∆∞ vi·ªán Gemini v·ªõi key ƒë√£ ch·ªçn.
genai.configure(api_key=selected_key)
# Kh·ªüi t·∫°o m√¥ h√¨nh Gemini. 'gemini-2.5-flash' l√† m·ªôt l·ª±a ch·ªçn t·ªët, c√¢n b·∫±ng gi·ªØa t·ªëc ƒë·ªô v√† hi·ªáu nƒÉng.
model = genai.GenerativeModel('gemini-2.5-flash')

def extract_structured_info(text: str) -> str:
    """
    S·ª≠ d·ª•ng m√¥ h√¨nh Gemini ƒë·ªÉ chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n OCR ƒë√£ s·ª≠a th√†nh m·ªôt ƒë·ªëi t∆∞·ª£ng JSON c√≥ c·∫•u tr√∫c.
    """
    # Prompt l√† ph·∫ßn quan tr·ªçng nh·∫•t, n√≥ h∆∞·ªõng d·∫´n chi ti·∫øt cho LLM c√°ch h√†nh x·ª≠ v√† ƒë·ªãnh d·∫°ng ƒë·∫ßu ra.
    # M·ªôt prompt chi ti·∫øt, r√µ r√†ng v√† c√≥ nhi·ªÅu quy t·∫Øc s·∫Ω cho k·∫øt qu·∫£ ch√≠nh x√°c v√† ·ªïn ƒë·ªãnh h∆°n.
    prompt = f"""
B·∫°n l√† m·ªôt h·ªá th·ªëng chuy√™n gia AI th√¥ng minh ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë·ªÉ l√†m vi·ªác ph√¢n t√≠ch v√† OCR tr√≠ch xu·∫•t d·ªØ li·ªáu m·ªôt c√°ch ch√≠nh x√°c,Vai tr√≤ c·ªßa b·∫°n l√† m·ªôt "K·∫ø to√°n vi√™n Robot", chuy√™n x·ª≠ l√Ω h√≥a ƒë∆°n b√°n l·∫ª t·ª´ d·ªØ li·ªáu OCR th√¥, v·ªën th∆∞·ªùng kh√¥ng ho√†n h·∫£o c√≥ th·ªÉ b·ªã l·ªói, ch·ª©a l·ªói nh∆∞ sai ch√≠nh t·∫£, thi·∫øu k√Ω t·ª±, ho·∫∑c b·ªã m·ªù..
Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch vƒÉn b·∫£n ƒë∆∞·ª£c cung c·∫•p v√† h√£y **ch·ªâ tr√≠ch xu·∫•t nh·ªØng th√¥ng tin th·ª±c s·ª± c√≥ m·∫∑t r√µ r√†ng trong n·ªôi dung**, v√† tr·∫£ v·ªÅ d∆∞·ªõi ƒë·ªãnh d·∫°ng c·∫•u tr√∫c JSON nh∆∞ sau:

{{
  "store_name": string ho·∫∑c null,
  "website": string ho·∫∑c null,
  "address": string ho·∫∑c null,
  "payment_method": string ho·∫∑c null,
  "receipt_number": string ho·∫∑c null,
  "receipt_datetime": string ho·∫∑c null,
  "staff_name": string ho·∫∑c null,
  "items": [
    {{
      "name": string,
      "quantity": s·ªë ho·∫∑c null,
      "unit_price": s·ªë ho·∫∑c null,
      "total_price": s·ªë ho·∫∑c null
    }}
  ],
  "total_amount": s·ªë ho·∫∑c null,              // T·ªïng c·ªông
  "discount_amount": s·ªë ho·∫∑c null,           // Gi·∫£m gi√° (n·∫øu c√≥)
  "paid_amount": s·ªë ho·∫∑c null,               // ƒê√£ thanh to√°n
  "customer_paid": s·ªë ho·∫∑c null,             // Kh√°ch h√†ng ƒë∆∞a
  "change": s·ªë ho·∫∑c null                     // Ti·ªÅn th·ª´a ƒë∆∞·ª£c tr·∫£ l·∫°i
}}

***QUY TR√åNH SUY LU·∫¨N V√Ä TR√çCH XU·∫§T:***
*Ph·∫ßn th√¥ng tin h√≥a ƒë∆°n*

**Ph·∫ßn 1: Th√¥ng tin chung c·ªßa H√≥a ƒë∆°n**

*   **`store_name`**:
    *   **V·ªã tr√≠:** Th∆∞·ªùng n·∫±m ·ªü tr√™n c√πng, l√† d√≤ng ch·ªØ n·ªïi b·∫≠t nh·∫•t (in hoa, c·ª° ch·ªØ l·ªõn).
    *   **T·ª´ kh√≥a lo·∫°i tr·ª´:** B·ªè qua c√°c t·ª´ chung chung nh∆∞ "H√ìA ƒê∆†N B√ÅN L·∫∫", "PHI·∫æU THANH TO√ÅN", "H√ìA ƒê∆†N", "PHI·∫æU", "B√ÅN H√ÄNG", "B√ÅN L·∫∫", "B√ÅN S·ªà".
    *   **Logic:** T√™n c·ª≠a h√†ng th∆∞·ªùng ƒëi k√®m v·ªõi c√°c t·ª´ nh∆∞ "C√¥ng ty", "TNHH", "C·ª≠a h√†ng", "Chi nh√°nh", "Trung t√¢m", "Si√™u th·ªã", "C·ª≠a h√†ng ti·ªán l·ª£i", "T√äN ƒê·∫†I L√ù". N·∫øu c√≥ nhi·ªÅu t√™n, ∆∞u ti√™n t√™n ƒë·∫ßu ti√™n, t√™n in hoa, ho·∫∑c t√™n c√≥ d·∫•u c√¢u ƒë·∫∑c bi·ªát (v√≠ d·ª•: d·∫•u hai ch·∫•m, g·∫°ch ngang).

*   **`website`**:
    *   **D·∫•u hi·ªáu:** T√¨m ki·∫øm c√°c chu·ªói vƒÉn b·∫£n ch·ª©a "www.", ".com", ".vn", ".net", ho·∫∑c "website:", "web:".
    *   **X·ª≠ l√Ω l·ªói:** OCR c√≥ th·ªÉ ch√®n kho·∫£ng tr·∫Øng (v√≠ d·ª•: "www. ten cua hang .vn"). H√£y lo·∫°i b·ªè c√°c kho·∫£ng tr·∫Øng n√†y ƒë·ªÉ t·∫°o th√†nh m·ªôt URL h·ª£p l·ªá.

*   **`address`**:
    *   **T·ª´ kh√≥a:** T√¨m ki·∫øm "ƒê·ªãa ch·ªâ:", "ƒê/c:", "Dc:", "ƒê·ªãa ch·ªâ giao h√†ng:", "ƒê·ªãa ch·ªâ nh·∫≠n h√†ng:", "ƒê·ªãa ch·ªâ c·ª≠a h√†ng:".
    *   **N·ªôi dung:** Gi√° tr·ªã ph·∫£i ch·ª©a c√°c th√†nh ph·∫ßn c·ªßa m·ªôt ƒë·ªãa ch·ªâ (v√≠ d·ª•: "T·ªï", "Khu", "Ph·ªë" ,"S·ªë", "ƒê∆∞·ªùng", "Ph·ªë", "Ph∆∞·ªùng", "Qu·∫≠n", "TP",...). N·∫øu ƒë·ªãa ch·ªâ b·ªã ng·∫Øt th√†nh nhi·ªÅu d√≤ng, h√£y gh√©p ch√∫ng l·∫°i.

*   **`payment_method`**:
    *   **T·ª´ kh√≥a:** T√¨m "H√¨nh th·ª©c thanh to√°n", "HTTT", "Thanh to√°n b·∫±ng", "Ph∆∞∆°ng th·ª©c thanh to√°n", "Ph∆∞∆°ng th·ª©c thanh to√°n:", "H√¨nh th·ª©c thanh to√°n:", "Thanh to√°n:", "Ph∆∞∆°ng th·ª©c thanh to√°n:", "H√¨nh th·ª©c thanh to√°n:", "Thanh to√°n b·∫±ng:".
    *   **Suy lu·∫≠n:**
        *   N·∫øu th·∫•y "Ti·ªÅn m·∫∑t", "Cash", "Thanh to√°n ti·ªÅn m·∫∑t", "TI·ªÄN M·∫∂T","TIEN MAT" -> "Ti·ªÅn m·∫∑t".
        *   N·∫øu th·∫•y "Visa", "Mastercard", "JCB", "Th·∫ª", "Thanh to√°n th·∫ª", "Thanh to√°n b·∫±ng th·∫ª" -> "Th·∫ª".
        *   N·∫øu th·∫•y "Momo", "VNPay", "ZaloPay", "Thanh to√°n Momo", "Thanh to√°n VNPay", "Thanh to√°n ZaloPay" -> T√™n c·ªßa v√≠ ƒëi·ªán t·ª≠ ƒë√≥.
        *   **Logic ph·ª•:** N·∫øu c√≥ tr∆∞·ªùng `customer_paid` v√† `change`, ph∆∞∆°ng th·ª©c thanh to√°n g·∫ßn nh∆∞ ch·∫Øc ch·∫Øn l√† "Ti·ªÅn m·∫∑t".

*   **`receipt_number`**:
    *   **T·ª´ kh√≥a:** T√¨m "S·ªë Hƒê", "M√£ GD", "S·ªë GD", "S·ªë h√≥a ƒë∆°n", "Receipt No.", "S·ªë HD", "No.","S·ªë CT", "M√£ h√≥a ƒë∆°n", "M√£ giao d·ªãch", "S·ªë giao d·ªãch", "S·ªë ƒë∆°n h√†ng", "S·ªë ƒë∆°n h√†ng:", "M√£ ƒë∆°n h√†ng:", "M√£ giao d·ªãch:", "S·ªë giao d·ªãch:", "S·ªë ch·ª©ng t·ª´", "S·ªë ch·ª©ng t·ª´:", "M√£ ch·ª©ng t·ª´:", "M√£ ch·ª©ng t·ª´".
    *   **ƒê·∫∑c ƒëi·ªÉm:** Th∆∞·ªùng l√† m·ªôt chu·ªói k√Ω t·ª± ng·∫Øn g·ªìm ch·ªØ v√† s·ªë (alphanumeric). C·∫ßn ph√¢n bi·ªát r√µ r√†ng v·ªõi s·ªë ƒëi·ªán tho·∫°i ho·∫∑c ng√†y th√°ng.

*   **`receipt_datetime`**:
    *   **T·ª´ kh√≥a:** T√¨m "Ng√†y:", "Gi·ªù:", "Date:", "Time:", "Th·ªùi gian", "Ng√†y gi·ªù:","Ng√†y CT","Ng√†y b√°n", "Ng√†y gi·ªù giao d·ªãch:", "Ng√†y gi·ªù thanh to√°n:", "Ng√†y gi·ªù h√≥a ƒë∆°n", "Ng√†y l·∫≠p", "Ng√†y l·∫≠p h√≥a ƒë∆°n", "Ng√†y l·∫≠p h√≥a ƒë∆°n:", "Ng√†y gi·ªù l·∫≠p h√≥a ƒë∆°n:", "Ng√†y gi·ªù l·∫≠p h√≥a ƒë∆°n:".
    *   **Logic:** Ng√†y v√† gi·ªù c√≥ th·ªÉ n·∫±m tr√™n c√πng m·ªôt d√≤ng ho·∫∑c hai d√≤ng ri√™ng bi·ªát; h√£y k·∫øt h·ª£p ch√∫ng. C·ªë g·∫Øng chu·∫©n h√≥a v·ªÅ ƒë·ªãnh d·∫°ng `YYYY-MM-DDTHH:MM:SS`. N·∫øu kh√¥ng th·ªÉ, gi·ªØ nguy√™n chu·ªói g·ªëc.

*   **`staff_name`**:
    *   **T·ª´ kh√≥a:** T√¨m "Thu ng√¢n:", "Nh√¢n vi√™n:", "NV:", "Cashier:", "Nh√¢n vi√™n thu ng√¢n:", "Nh√¢n vi√™n b√°n h√†ng:", "NVBH", "Nh√¢n vi√™n ph·ª•c v·ª•:", "Nh√¢n vi√™n giao h√†ng:", "Nh√¢n vi√™n giao h√†ng:", "Nh√¢n vi√™n giao h√†ng:".
    *   **ƒê·∫∑c ƒëi·ªÉm:** Gi√° tr·ªã ph·∫£i l√† t√™n ng∆∞·ªùi, kh√¥ng ph·∫£i t√™n c√¥ng ty hay m·ªôt c·ª•m t·ª´ chung, c√≥ th·ªÉ c√≥ c·∫£ m√£ s·ªë nh√¢n vi√™n. N·∫øu c√≥ nhi·ªÅu t√™n, ∆∞u ti√™n t√™n ƒë·∫ßu ti√™n.

**Ph·∫ßn 2: Danh s√°ch s·∫£n ph·∫©m (`items`)**

*   **X√°c ƒë·ªãnh khu v·ª±c:** T√¨m v√πng vƒÉn b·∫£n c√≥ c·∫•u tr√∫c gi·ªëng b·∫£ng, th∆∞·ªùng n·∫±m gi·ªØa th√¥ng tin c·ª≠a h√†ng v√† ph·∫ßn t·ªïng ti·ªÅn. C√°c c·ªôt th∆∞·ªùng l√† "T√™n h√†ng", "SL" (S·ªë l∆∞·ª£ng), "ƒê∆°n gi√°", "Th√†nh ti·ªÅn".
*   **Tr√≠ch xu·∫•t t·ª´ng d√≤ng:**
    *   `name`: L√† ph·∫ßn vƒÉn b·∫£n m√¥ t·∫£ s·∫£n ph·∫©m. T√™n s·∫£n ph·∫©m c√≥ th·ªÉ k√©o d√†i nhi·ªÅu d√≤ng; h√£y gh√©p ch√∫ng l·∫°i, t√™n c√≥ th·ªÉ kh√¥ng c√≥ d·∫•u c√¢u ho·∫∑c vi·∫øt hoa, c√≥ th·ªÉ c√≥ th√™m ch·ªØ s·ªë ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát.
    *   `quantity`: Th∆∞·ªùng l√† m·ªôt s·ªë nguy√™n nh·ªè (1, 2, 3...) ƒë·ªëi v·ªõi s·ªë l∆∞·ª£ng, n·∫øu l√† m·ªôt s·ªë th·ª±c (0.01, 0.1, 1.0, 10.0, 0.02, 0.5, 9.0, ...) ƒë·ªëi v·ªõi tr·ªçng l∆∞·ª£ng. N·∫øu kh√¥ng c√≥, m·∫∑c ƒë·ªãnh l√† `1`, nh∆∞ng n·∫øu kh√¥ng h·ª£p l√Ω th√¨ ƒë·ªÉ `null`.
    *   `unit_price`: Gi√° c·ªßa m·ªôt ƒë∆°n v·ªã s·∫£n ph·∫©m, th∆∞·ªùng l√† m·ªôt s·ªë th·ª±c (v√≠ d·ª•: 10.000, 20.500). N·∫øu kh√¥ng c√≥ gi√° r√µ r√†ng, ƒë·ªÉ `null`.
    *   `total_price`: T·ªïng ti·ªÅn cho d√≤ng ƒë√≥, th∆∞·ªùng l√† m·ªôt s·ªë th·ª±c (v√≠ d·ª•: 20.000, 41.000). N·∫øu kh√¥ng c√≥ gi√° r√µ r√†ng, ƒë·ªÉ `null`
    *   **Quy t·∫Øc x√°c th·ª±c V√ÄNG:** S·ª≠ d·ª•ng c√¥ng th·ª©c `quantity * unit_price ‚âà total_price` ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c c·ªôt n√†o l√† c·ªôt n√†o, ngay c·∫£ khi ti√™u ƒë·ªÅ c·ªôt b·ªã thi·∫øu ho·∫∑c sai do OCR.

*Ph·∫ßn gi√° tr·ªã t·ªïng ti·ªÅn v√† thanh to√°n*

1.  **Ph√¢n t√≠ch ng·ªØ nghƒ©a (Semantic Analysis):**
    *   S·ª≠ d·ª•ng danh s√°ch t·ª´ kh√≥a sau ƒë·ªÉ g√°n nh√£n cho c√°c gi√° tr·ªã s·ªë:
        *   `total_amount`: "T·ªïng c·ªông", "C·ªông ti·ªÅn h√†ng", "Th√†nh ti·ªÅn", "T·ªïng ti·ªÅn", "T·ªïng ti·ªÅn h√†ng", "T·ªïng ti·ªÅn thanh to√°n", "T·ªïng ti·ªÅn h√≥a ƒë∆°n", "T·ªïng ti·ªÅn ph·∫£i tr·∫£", "T·ªïng ti·ªÅn thanh to√°n", "T·ªïng ti·ªÅn thanh to√°n h√≥a ƒë∆°n", "T·ªïng ti·ªÅn thanh to√°n h√≥a ƒë∆°n", "T·ªïng ti·ªÅn thanh to√°n h√≥a ƒë∆°n", "C·ªông ti·ªÅn h√†ng".
        *   `discount_amount`: "Gi·∫£m gi√°", "Chi·∫øt kh·∫•u", "Khuy·∫øn m√£i", "Gi·∫£m gi√° ti·ªÅn h√†ng", "Gi·∫£m gi√° ti·ªÅn", "Gi·∫£m gi√° t·ªïng ti·ªÅn", "Gi·∫£m gi√° thanh to√°n", "Gi·∫£m gi√° h√≥a ƒë∆°n", "Gi·∫£m gi√° thanh to√°n h√≥a ƒë∆°n", "Gi·∫£m gi√° thanh to√°n h√≥a ƒë∆°n", "Gi·∫£m gi√° thanh to√°n h√≥a ƒë∆°n".
        *   `paid_amount`: "T·ªïng ti·ªÅn thanh to√°n", "Kh√°ch c·∫ßn tr·∫£", "Ph·∫£i tr·∫£", "T·ªïng thanh to√°n", "Thanh to√°n", "ƒê√£ thanh to√°n", "T·ªïng ti·ªÅn thanh to√°n", "T·ªïng ti·ªÅn thanh to√°n h√≥a ƒë∆°n", "T·ªïng ti·ªÅn thanh to√°n h√≥a ƒë∆°n", "T·ªïng ti·ªÅn thanh to√°n h√≥a ƒë∆°n", "T·ªïng ti·ªÅn gi·∫£m gi√°", "T·ªïng ti·ªÅn gi·∫£m gi√° h√≥a ƒë∆°n", "T·ªïng".
        *   `customer_paid`: "Ti·ªÅn kh√°ch ƒë∆∞a", "Ti·ªÅn kh√°ch tr·∫£", "Ti·ªÅn m·∫∑t", "Kh√°ch ƒë∆∞a", "Kh√°ch thanh to√°n", "Kh√°ch tr·∫£", "Kh√°ch thanh to√°n b·∫±ng ti·ªÅn m·∫∑t", "Kh√°ch thanh to√°n b·∫±ng ti·ªÅn m·∫∑t", "Kh√°ch h√†ng thanh to√°n", "Kh√°ch h√†ng tr·∫£ ti·ªÅn", "Kh√°ch h√†ng thanh to√°n b·∫±ng ti·ªÅn m·∫∑t".
        *   `change`: "Ti·ªÅn th·ªëi l·∫°i", "Ti·ªÅn th·ª´a", "Tr·∫£ l·∫°i", "Th·ª´a", "Ti·ªÅn tr·∫£ l·∫°i", "Ti·ªÅn tr·∫£ kh√°ch", "Ti·ªÅn tr·∫£ l·∫°i kh√°ch", "Ti·ªÅn tr·∫£ l·∫°i kh√°ch h√†ng", "Ti·ªÅn tr·∫£ l·∫°i kh√°ch h√†ng".
    *   H√£y linh ho·∫°t v·ªõi c√°c bi·∫øn th·ªÉ do l·ªói OCR (v√≠ d·ª•: "T·ªëng c·ªçng", "Giam gia" thay v√¨ "T·ªïng c·ªông", "Gi·∫£m gi√°" thay v√¨ "Gi·∫£m gi√°", "Kh√°ch h√†ng ƒë∆∞a" thay v√¨ "Kh√°ch ƒë∆∞a", v.v.), n·∫øu ch·ªØ in hoa th√¨ ∆∞u ti√™n ch·ªØ in hoa, n·∫øu ch·ªØ in th∆∞·ªùng th√¨ ∆∞u ti√™n ch·ªØ in th∆∞·ªùng.

2.  **Ki·ªÉm tra ch√©o b·∫±ng Logic To√°n h·ªçc (Logical Cross-Validation):**
    *   **Quy t·∫Øc 1:** `total_amount` - `discount_amount` ph·∫£i x·∫•p x·ªâ b·∫±ng `paid_amount`. S·ª≠ d·ª•ng quy t·∫Øc n√†y ƒë·ªÉ x√°c ƒë·ªãnh `paid_amount` n·∫øu n√≥ kh√¥ng ƒë∆∞·ª£c ghi r√µ.
    *   **Quy t·∫Øc 2:** `customer_paid` - `paid_amount` ph·∫£i b·∫±ng `change`. D√πng quy t·∫Øc n√†y ƒë·ªÉ x√°c th·ª±c c·∫£ ba gi√° tr·ªã.
    *   **Quy t·∫Øc 3:** N·∫øu ch·ªâ c√≥ m·ªôt con s·ªë t·ªïng duy nh·∫•t tr√™n h√≥a ƒë∆°n, n√≥ th∆∞·ªùng l√† `total_amount` (v√† c≈©ng l√† `paid_amount` n·∫øu kh√¥ng c√≥ gi·∫£m gi√°).

3.  **X·ª≠ l√Ω D·ªØ li·ªáu kh√¥ng ho√†n h·∫£o (Imperfection Handling):**
    *   ƒê·ªëi v·ªõi c√°c con s·ªë, h√£y chu·∫©n h√≥a ch√∫ng: lo·∫°i b·ªè k√Ω t·ª± kh√¥ng ph·∫£i s·ªë (ngo·∫°i tr·ª´ d·∫•u th·∫≠p ph√¢n), di·ªÖn gi·∫£i ƒë√∫ng c√°c d·∫•u ph√¢n c√°ch h√†ng ngh√¨n/th·∫≠p ph√¢n.
    *   N·∫øu m·ªôt d√≤ng s·∫£n ph·∫©m thi·∫øu s·ªë l∆∞·ª£ng, m·∫∑c ƒë·ªãnh l√† `1` n·∫øu h·ª£p l√Ω. N·∫øu kh√¥ng, ƒë·ªÉ `null`.

4.  **X·ª≠ l√Ω l·ªói OCR:** H√£y nh·∫≠n di·ªán v√† b·ªè qua c√°c l·ªói ph·ªï bi·∫øn nh∆∞ nh·∫ßm l·∫´n gi·ªØa 'o' v√† '0', 'l' v√† '1', 's' v√† '5', c√°c d·∫•u ch·∫•m/ph·∫©y trong s·ªë ti·ªÅn kh√¥ng ƒë√∫ng v·ªã tr√≠.     
    
üîí **Quy t·∫Øc nghi√™m ng·∫∑t**:
- Kh√¥ng b·ªãa, kh√¥ng suy lu·∫≠n n·∫øu th√¥ng tin KH√îNG R√ï trong vƒÉn b·∫£n.
- N·∫øu th√¥ng tin kh√¥ng th·ªÉ ƒë∆∞·ª£c x√°c ƒë·ªãnh m·ªôt c√°ch logic ho·∫∑c kh√¥ng c√≥ trong vƒÉn b·∫£n, h√£y ƒë·∫∑t l√† `null`.
- KH√îNG t·ª± t·∫°o s·∫£n ph·∫©m, t√™n nh√¢n vi√™n, t√™n s·∫£n ph·∫©m, m√£ h√≥a ƒë∆°n, ƒë·ªãa ch·ªâ hay ng√†y th√°ng n·∫øu kh√¥ng c√≥, h√£y ƒë·∫∑t l√† `null`.
- KH√îNG ƒë∆∞a ra b·∫•t k·ª≥ gi·∫£i th√≠ch, ghi ch√∫ hay vƒÉn b·∫£n n√†o ngo√†i JSON thu·∫ßn.
- ∆ØU TI√äN s·ª± hi·ªán di·ªán r√µ r√†ng: M·ªôt gi√° tr·ªã ƒë∆∞·ª£c ghi r√µ r√†ng b√™n c·∫°nh t·ª´ kh√≥a (`T·ªïng c·ªông: 50.000`) lu√¥n ƒë∆∞·ª£c ∆∞u ti√™n h∆°n m·ªôt gi√° tr·ªã suy lu·∫≠n.
- ƒê·∫£m b·∫£o JSON ƒë√∫ng chu·∫©n ƒë·ªÉ c√≥ th·ªÉ `json.loads(...)` m√† kh√¥ng l·ªói.

=== VƒÉn b·∫£n h√≥a ƒë∆°n g·ªëc ===
\"\"\"{text}\"\"\"
"""
    # G·ª≠i prompt (bao g·ªìm c·∫£ h∆∞·ªõng d·∫´n v√† d·ªØ li·ªáu) ƒë·∫øn API c·ªßa Gemini.
    response = model.generate_content(prompt)
    # Tr·∫£ v·ªÅ ph·∫ßn vƒÉn b·∫£n trong ph·∫£n h·ªìi c·ªßa m√¥ h√¨nh.
    return response.text

# --- VI. C√ÅC H√ÄM TI·ªÜN √çCH V√Ä PIPELINE CH√çNH ---

def save_json_from_image_path(image_path: str, data: dict, output_root: str = "output_structured"):
    """
    L∆∞u d·ªØ li·ªáu dict v√†o m·ªôt file JSON. T√™n file JSON s·∫Ω gi·ªëng t√™n file ·∫£nh.
    """
    # L·∫•y t√™n file t·ª´ ƒë∆∞·ªùng d·∫´n v√† lo·∫°i b·ªè ph·∫ßn m·ªü r·ªông (v√≠ d·ª•: .jpg, .png).
    image_filename = os.path.splitext(os.path.basename(image_path))[0]
    
    # ƒê·∫£m b·∫£o th∆∞ m·ª•c ƒë·∫ßu ra t·ªìn t·∫°i.
    os.makedirs(output_root, exist_ok=True)
    
    # T·∫°o ƒë∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn file JSON s·∫Ω ƒë∆∞·ª£c l∆∞u.
    json_path = os.path.join(output_root, image_filename + ".json")
    
    # Ghi d·ªØ li·ªáu dict v√†o file JSON.
    # `ensure_ascii=False` ƒë·ªÉ gi·ªØ l·∫°i c√°c k√Ω t·ª± ti·∫øng Vi·ªát.
    # `indent=2` ƒë·ªÉ file JSON ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng ƒë·∫πp, d·ªÖ ƒë·ªçc.
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu c√≥ c·∫•u tr√∫c v√†o: {json_path}")

def process_receipt(image_path: str):
    """
    H√†m ch√≠nh, ƒëi·ªÅu ph·ªëi to√†n b·ªô pipeline x·ª≠ l√Ω m·ªôt h√≥a ƒë∆°n t·ª´ A ƒë·∫øn Z.
    """
    print("\n" + "="*50)
    print(f"üöÄ B·∫Øt ƒë·∫ßu pipeline x·ª≠ l√Ω cho: {os.path.basename(image_path)}")
    print("="*50)
    
    # B∆∞·ªõc 1: Tr√≠ch xu·∫•t vƒÉn b·∫£n th√¥ t·ª´ ·∫£nh b·∫±ng OCR.
    print("üîç ƒêang th·ª±c hi·ªán OCR...")
    raw_text = extract_text_from_image(image_path)
    
    # B∆∞·ªõc 2: S·ª≠a l·ªói ch√≠nh t·∫£ v√† l·ªói OCR.
    print("üß† ƒêang s·ª≠a l·ªói vƒÉn b·∫£n...")
    corrected_text = correct_text(raw_text)
    
    # B∆∞·ªõc 3: Tr√≠ch xu·∫•t th√¥ng tin c√≥ c·∫•u tr√∫c b·∫±ng LLM.
    print("üì¶ ƒêang tr√≠ch xu·∫•t c√°c tr∆∞·ªùng d·ªØ li·ªáu c√≥ c·∫•u tr√∫c...")
    structured_data_str = extract_structured_info(corrected_text)
    
    # B∆∞·ªõc 4: L√†m s·∫°ch chu·ªói JSON tr·∫£ v·ªÅ t·ª´ LLM.
    # LLM ƒë√¥i khi tr·∫£ v·ªÅ chu·ªói JSON n·∫±m trong kh·ªëi m√£ markdown (```json ... ```).
    cleaned_struct_data = structured_data_str.strip()
    if cleaned_struct_data.startswith("```json"):
        cleaned_struct_data = cleaned_struct_data.removeprefix("```json").strip()
    if cleaned_struct_data.endswith("```"):
        cleaned_struct_data = cleaned_struct_data.removesuffix("```").strip()
        
    # B∆∞·ªõc 5: Chuy·ªÉn chu·ªói JSON th√†nh ƒë·ªëi t∆∞·ª£ng dict c·ªßa Python.
    try:
        struct_data_dict = json.loads(cleaned_struct_data)
        print("‚úÖ D·ªØ li·ªáu c√≥ c·∫•u tr√∫c ƒë√£ ƒë∆∞·ª£c parse th√†nh c√¥ng.")
    except json.JSONDecodeError as e:
        # N·∫øu LLM tr·∫£ v·ªÅ m·ªôt chu·ªói kh√¥ng ph·∫£i l√† JSON h·ª£p l·ªá, b√°o l·ªói v√† tr·∫£ v·ªÅ chu·ªói th√¥.
        print(f"‚ùå L·ªói khi parse JSON: {e}")
        return cleaned_struct_data
        
    # B∆∞·ªõc 6 (T√πy ch·ªçn): L∆∞u file JSON xu·ªëng ƒëƒ©a.
    # print("üíæ ƒêang l∆∞u d·ªØ li·ªáu c√≥ c·∫•u tr√∫c...")
    # save_json_from_image_path(image_path, struct_data_dict)
    
    print("üéâ Pipeline ƒë√£ ho√†n t·∫•t th√†nh c√¥ng!")
    # Tr·∫£ v·ªÅ k·∫øt qu·∫£ cu·ªëi c√πng l√† m·ªôt ƒë·ªëi t∆∞·ª£ng dict.
    return struct_data_dict